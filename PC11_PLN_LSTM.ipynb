{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMsNyA3WPrER"
      },
      "source": [
        "##**Notebook PC#11**\n",
        "\n",
        "## Encoder-Decoder LSTM for Natural Language Processing.\n",
        "\n",
        "**Professor:** Fernando J. Von Zuben <br>\n",
        "**Aluno(a):** Ariel GÃ³es de Castro <br>\n",
        "**Aluno(a):** Francisco Germano Vogt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1xumdIFHDdrn"
      },
      "outputs": [],
      "source": [
        "from random import seed\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fspvFmS6Ddro"
      },
      "outputs": [],
      "source": [
        "def random_sum_pairs(n_examples, n_numbers, largest):\n",
        "    X,y = list(), list()\n",
        "    for i in range(n_examples):\n",
        "        in_pattern=[randint(1,largest) for _ in range(n_numbers)]\n",
        "        out_pattern = sum(in_pattern)\n",
        "        X.append(in_pattern)\n",
        "        y.append(out_pattern)\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zzr9HXh8Ddrp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3, 10]] [13]\n"
          ]
        }
      ],
      "source": [
        "seed(1)\n",
        "n_samples =1\n",
        "n_numbers = 2\n",
        "largest = 10\n",
        "X,y = random_sum_pairs(n_samples, n_numbers, largest)\n",
        "print(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QWTgrmmuDdrp"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "from math import log10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NbBlwQTvDdrp"
      },
      "outputs": [],
      "source": [
        "def to_string(X,y,n_numbers,largest):\n",
        "    max_length = n_numbers*ceil(log10(largest+1)) + n_numbers - 1\n",
        "    Xstr = list()\n",
        "    for pattern in X:\n",
        "        strp = '+'.join([str(n) for n in pattern])\n",
        "        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
        "        Xstr.append(strp)\n",
        "    maxlength = ceil(log10(n_numbers*(largest+1)))\n",
        "    ystr = list()\n",
        "    for pattern in y:\n",
        "        strp = str(pattern)\n",
        "        strp = ''.join([' 'for _ in range(maxlength-len(strp))]) + strp\n",
        "        ystr.append(strp)\n",
        "    return Xstr, ystr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fAVqEpSsDdrq"
      },
      "outputs": [],
      "source": [
        "seed(1)\n",
        "n_samples = 1\n",
        "n_numbers = 2\n",
        "largest = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u-m3UD5uDdrq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3, 10]] [13]\n",
            "[' 3+10'] ['13']\n"
          ]
        }
      ],
      "source": [
        "X,y = random_sum_pairs(n_samples, n_numbers, largest)\n",
        "print(X,y)\n",
        "\n",
        "X,y = to_string(X,y,n_numbers,largest)\n",
        "print(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qwQXLtpfDdrq"
      },
      "outputs": [],
      "source": [
        "alphabet = ['0','1','2','3','4','5','6','7','8','9','+',' ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GXKcXm8JDdrq"
      },
      "outputs": [],
      "source": [
        "def integer_encode(X,y,alphabet):\n",
        "    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
        "    Xenc = list()\n",
        "    for pattern in X:\n",
        "        integer_encoded = [char_to_int[char] for char in pattern]\n",
        "        Xenc.append(integer_encoded)\n",
        "    yenc = list()\n",
        "    for pattern in y:\n",
        "        integer_encoded = [char_to_int[char] for char in pattern]\n",
        "        yenc.append(integer_encoded)\n",
        "    return Xenc, yenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BjD9y1M2Ddrr"
      },
      "outputs": [],
      "source": [
        "X,y = integer_encode(X,y,alphabet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v02pwsYYDdrr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[11, 3, 10, 1, 0]] [[1, 3]]\n"
          ]
        }
      ],
      "source": [
        "print(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vad64QkqDdrr"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(X,y,max_int):\n",
        "    Xenc = list()\n",
        "    for seq in X:\n",
        "        pattern = list()\n",
        "        for index in seq:\n",
        "            vector = [0 for _ in range(max_int)]\n",
        "            vector[index] = 1\n",
        "            pattern.append(vector)\n",
        "        Xenc.append(pattern)\n",
        "\n",
        "    yenc = list()\n",
        "    for seq in y:\n",
        "        pattern = list()\n",
        "        for index in seq:\n",
        "            vector = [0 for _ in range(max_int)]\n",
        "            vector[index] = 1\n",
        "            pattern.append(vector)\n",
        "        yenc.append(pattern)\n",
        "    return Xenc, yenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W_tCfgMPDdrr"
      },
      "outputs": [],
      "source": [
        "X,y = one_hot_encode(X,y,len(alphabet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R7VdCFIgDdrr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] [[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"
          ]
        }
      ],
      "source": [
        "print(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xVdn4BqyDdrs"
      },
      "outputs": [],
      "source": [
        "def generate_data(n_samples,n_numbers, largest, alphabet):\n",
        "    X,y = random_sum_pairs(n_samples,n_numbers,largest)\n",
        "    X,y = to_string(X,y,n_numbers,largest)\n",
        "    X,y = integer_encode(X,y,alphabet)\n",
        "    X,y = one_hot_encode(X,y,len(alphabet))\n",
        "    X,y = array(X), array(y)\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RDp9JqNkDdrs"
      },
      "outputs": [],
      "source": [
        "def invert(seq,alphabet):\n",
        "    int_to_char = dict((i,c) for i,c in enumerate(alphabet))\n",
        "    strings  = list()\n",
        "    for pattern in seq:\n",
        "        string = int_to_char[argmax(pattern)]\n",
        "        strings.append(string)\n",
        "    return ''.join(strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7BqRNPCkDdrs"
      },
      "outputs": [],
      "source": [
        "n_terms = 3\n",
        "largest = 10\n",
        "alphabet = [str(x) for x in range(10)] + ['+', ' ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PijAMEFxDdrs"
      },
      "outputs": [],
      "source": [
        "n_chars = len(alphabet)\n",
        "n_in_seq_length = n_terms*ceil(log10(largest+1)) +n_terms-1\n",
        "n_out_seq_length = ceil(log10(n_terms*(largest+1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RR9pPe1oDdrs"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Gxs5FSIwDdrs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-30 20:55:58.239600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.243423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.243534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.244112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-30 20:55:58.244830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.244955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.245044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.590807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.590925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.591013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-30 20:55:58.591086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9630 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 75)                26400     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 2, 75)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 2, 50)             25200     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 2, 12)            612       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,212\n",
            "Trainable params: 52,212\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(75, input_shape=(n_in_seq_length,n_chars)))\n",
        "model.add(RepeatVector(n_out_seq_length))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_chars,activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vG1QwiwFDdrt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-30 20:56:02.426169: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 39s 5ms/step - loss: 0.4040 - accuracy: 0.8781\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3170165300>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X,y = generate_data(75000,n_terms,largest,alphabet)\n",
        "model.fit(X,y,epochs=1,batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pBWMp85oDdrt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.023789, Accuracy: 99.500000\n"
          ]
        }
      ],
      "source": [
        "X,y = generate_data(100,n_terms,largest,alphabet)\n",
        "loss,acc = model.evaluate(X,y,verbose=0)\n",
        "print('Loss: %f, Accuracy: %f' %(loss,acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XjorRbDxDdrt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   3+6+3 = 12 (expect 12)\n",
            "   7+5+2 = 14 (expect 14)\n",
            "  10+6+4 = 20 (expect 20)\n",
            "   5+9+2 = 16 (expect 16)\n",
            "  2+4+10 = 16 (expect 16)\n",
            " 7+10+10 = 27 (expect 27)\n",
            "   2+3+8 = 13 (expect 13)\n",
            "   4+1+8 = 13 (expect 13)\n",
            "   1+3+5 =  9 (expect  9)\n",
            "   9+6+1 = 16 (expect 16)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    X,y = generate_data(1,n_terms,largest,alphabet)\n",
        "    yhat = model.predict(X,verbose=0)\n",
        "    in_seq = invert(X[0],alphabet)\n",
        "    out_seq = invert(y[0],alphabet)\n",
        "    predicted = invert(yhat[0],alphabet)\n",
        "    print('%s = %s (expect %s)' %(in_seq,predicted,out_seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mulXq9ZZKkX5"
      },
      "source": [
        "<font color=\"green\">\n",
        "Atividade (a) <br>\n",
        "Como sÃ£o gerados os dados de treinamento?\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGsvW_2eTpfB"
      },
      "source": [
        "**Resposta:**\n",
        "\n",
        "Vamos explicar as funÃ§Ãµes que sÃ£o chamadas dentro da funÃ§Ã£o `generate_data` para entender o processo:\n",
        "\n",
        "```python\n",
        "def generate_data(n_samples,n_numbers, largest, alphabet):\n",
        "    X,y = random_sum_pairs(n_samples,n_numbers,largest)\n",
        "    X,y = to_string(X,y,n_numbers,largest)\n",
        "    X,y = integer_encode(X,y,alphabet)\n",
        "    X,y = one_hot_encode(X,y,len(alphabet))\n",
        "    X,y = array(X), array(y)\n",
        "    return X,y\n",
        "```\n",
        "\n",
        "#### Na funÃ§Ã£o `random_sum_pairs` temos os seguintes parÃ¢metros de entrada para gerar pares de somas aleatÃ³rios:\n",
        "\n",
        "* _n_examples:_ o nÃºmero de exemplos de pares entrada-saÃ­da (saÃ­da esperada/rotulada) a serem gerados;\n",
        "* _n_numbers:_ o nÃºmero de inteiros em cada entrada. Essa entrada Ã© uma lista de tamanho fixo definida por `n_numbers`;\n",
        "* _largest:_ O maior nÃºmero que cada inteiro aleatÃ³rio da entrada X pode assumir (definido por `largest`).\n",
        "\n",
        "No exemplo abaixo, do prÃ³prio cÃ³digo:\n",
        "```\n",
        "seed(1)  # Set the seed for reproducibility\n",
        "n_samples = 1  # Number of samples to generate\n",
        "n_numbers = 2  # Number of numbers in each input list\n",
        "largest = 10  # Largest possible number in the input list\n",
        "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
        "print(X, y)\n",
        "```\n",
        "\n",
        "SaÃ­da:\n",
        "```\n",
        "[[3, 10]] [13]\n",
        "```\n",
        "\n",
        "No caso acima, temos uma amostra gerada (`n_samples=1`), onde os elementos de X sÃ£o a lista [3,10] de tamanho `n_numbers=2` e cada valor nÃ£o ultrapassa o valor mÃ¡ximo de 10 (`largest=10`). JÃ¡ a saÃ­da Y, representa a soma esperada/rotulada.\n",
        "\n",
        "\n",
        "#### Na funÃ§Ã£o `to_string`, converte-se a saÃ­da anterior:\n",
        "\n",
        "SaÃ­da:\n",
        "```\n",
        "[' 3+10'] ['13']\n",
        "```\n",
        "\n",
        "Essa representaÃ§Ã£o vai ser posteriormente utilizada na chamada seguinte (`integer_encode`).\n",
        "\n",
        "#### Para a funÃ§Ã£o `integer_encode` temos:\n",
        "\n",
        "a declaraÃ§Ã£o de uma alfabeto de sÃ­mbolos que serÃ¡ utilizado pelo modelo: <br>\n",
        "`alphabet = ['0','1','2','3','4','5','6','7','8','9','+',' ']`\n",
        "\n",
        "A funÃ§Ã£o `integer_encode` recebe as string de entrada (X) e saÃ­da esperada (y) e converte cada sÃ­mbolo de acordo com a posiÃ§Ã£o de Ã­ndices (comeÃ§ando em zero) da lista `alphabet`.\n",
        "\n",
        "Por exemplo, a saÃ­da esperada no nosso exemplo seria:\n",
        "```\n",
        "[[11, 3, 10, 1, 0]] [[1, 3]]\n",
        "```\n",
        "\n",
        "onde 11 Ã© o Ãºltimo Ã­ndice da lista (' '), 3 Ã© o prÃ³prio 3, 10 Ã© o sÃ­mbolo '+', e assim por diante.\n",
        "\n",
        "\n",
        "## Para a funÃ§Ã£o `one_hot_encode`:\n",
        "\n",
        "Convertemos a saÃ­da numÃ©rica e para facilitar o aprendizado, converte-se cada sÃ­mbolo que serÃ¡ utilizado em uma representaÃ§Ã£o binÃ¡ria Ãºnica, chamada one-hot-econding. Dessa forma, cada sÃ­mbolo pode ser visto como uma classe separada e evitar falsas interpretaÃ§Ãµes da rede neural que poderiam ocorrer caso utilizÃ¡ssemos as strings  (e.g., '0' visto como 0, '1' visto como 1, etc.)\n",
        "\n",
        "Por fim, a Ãºltima linha garante que tanto o X quanto y estejam em formato de array antes de retornar a saÃ­da da funÃ§Ã£o `generate_data`.\n",
        "\n",
        "#### Resumindo:\n",
        "Geramos pares de nÃºmeros e a saÃ­da esperada para que o modelo aprenda a manipular os sÃ­mbolos. PorÃ©m, realiza-se conversÃµes intermediÃ¡rias (e.g., `integer_encode`) para utilizarmos os dados como one-hot-encoding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn1TbpOT_ew-"
      },
      "source": [
        "<font color=\"green\">\n",
        "Atividade (b) <br>\n",
        "Como uma calculadora simples pode operar baseada no conceito de traduÃ§Ã£o de frases, ou seja, sem realizar operaÃ§Ãµes algÃ©bricas?\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xRF9vul_ew_"
      },
      "source": [
        "**Resposta:** <br>\n",
        "\n",
        "O modelo analisa as entradas como um conjunto de sÃ­mbolos e saÃ­das que devem ser corretamente previstas. Por exemplo, podemos tranformar a sequÃªncia \"3+6\" em outra sequÃªncia que representa a soma desses nÃºmeros, totalizando \"9\". Logo, o problema consiste em mapear uma sequÃªncia para outra sequÃªncia (a.k.a., seq2seq). \n",
        "\n",
        "A entrada Ã© processada e convertida para um vetor de tamanho fixo, capturando as informaÃ§Ãµes de toda a sequÃªncia de entrada. Logo, o vetor de contexto gera a sequÃªncia de saÃ­da (um sÃ­mbolo por vez).\n",
        "\n",
        "Durante o treinamento, o modelo aprende a reconhecer padrÃµes em sequÃªncias, tokenizando as entradas (e.g., \"3+6\") como uma sequÃªncia de vectores one-hot-econded. O mesmo acontece com a saÃ­da \"9\".\n",
        "\n",
        "Nesta arquitetura, temos os principais componentes:\n",
        "* Camada LSTM: codifica a sequÃªncia de entrada em um vetor de comprimento fixo.\n",
        "* Camada RepeatVector: repete o vetor codificado para corresponder ao comprimento da sequÃªncia de saÃ­da.\n",
        "* Segunda camada LSTM: Decodifica o vetor repetido em uma sequÃªncia de saÃ­da.\n",
        "* Camada TimeDistributed: aplica uma camada densa a cada intervalo de tempo da sequÃªncia de saÃ­da para produzir a saÃ­da final.\n",
        "\n",
        "A cada iteraÃ§Ã£o os pesos sÃ£o ajustados. A camada `RepeatVector` cria uma sequÃªncia de comprimento fixo a partir do vetor de contexto codificado para o decodificador. Este vetor de contexto repetido Ã© entÃ£o alimentado na segunda camada LSTM. A funÃ§Ã£o `softmax` transforma a saÃ­da da rede em probabilidades, que sÃ£o esperadas pela funÃ§Ã£o de perda categorical_crossentropy. Durante o treinamento, a perda de entropia cruzada medirÃ¡ a diferenÃ§a entre a distribuiÃ§Ã£o de probabilidade prevista (da saÃ­da softmax) e a distribuiÃ§Ã£o verdadeira (verdade fundamental codificada one-hot).\n",
        " \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_gpu_python-3-10",
      "language": "python",
      "name": "tf_gpu_python10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
